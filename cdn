#!/bin/bash
# +---------------------------------------------------------------------------+
# ! Website-CDN-Parser                                                        !
# ! **************************************************************************+
# ! Dieses Skript nimmt eine Startseite für eine Website ,
# ! im Format z.B. https://www.mysite.de/Startseite,
# ! und den Rumpfnamen für eine Webarchiv-Datei,
# ! im Format z.B. WEB-www.mysite.de-20191219 .
# ! Das Skript durchsucht die Starseite nach inkludierten Style- 
# ! Skriptdateien. Das macht das Python-Skript "cdnparse", welches 
# ! als Voraussetzung für dieses Skript installiert sein muss !
# ! Das Skript sammelt gefundene URLs in der Datei cdn.txt .
# ! Diese Datei wird im aktuellen Verzeichnis ($PWD) angelegt.
# ! Anschließend werden mit wpull alle gefundenen Skripte und Styles
# ! aus dem Internet heruntergeladen und in einem Webarchiv archiviert.
# +---------------------------------------------------------------------------+
# ! Autor           | Datum      | Grund                                      !
# +---------------------------------------------------------------------------+
# ! Ingolf Kuss     | 19.12.2019 | Neuanlage                                  !
# +---------------------------------------------------------------------------+

# SITE=https://www.alumnat-sankt-michael-boppard.de/
SITE=$1
WARCNAME=$2
USERAGENT=$3
COOKIE=$4
WAITPARAM=$5
CDXFILE=""
if [ $# -gt 5 ]; then
  CDXFILE=$6
fi
echo "Starting CDN-Gathering"
echo "SITE=$SITE"
echo "WARCNAME=$WARCNAME"
echo "COOKIE=$COOKIE"
echo "WAITPARAM=$WAITPARAM"
echo "CDXFILE=$CDXFILE"

WAITSECS=0
if [[ $WAITPARAM =~ ^wait= ]]; then
    WAITSECS="${WAITPARAM//wait=/}"
fi
echo "WAITSECS=$WAITSECS"

CDNPARSE=/opt/toscience/python3/bin/cdnparse
WPULL=/opt/toscience/python3/bin/wpull
# cdns="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"
echo "executing CDNParser: $CDNPARSE -a  -u \"$USERAGENT\" -c \"$COOKIE\" -w \"$WAITSECS\" $SITE > cdn.txt"
$CDNPARSE -a  -u "$USERAGENT" -c "$COOKIE" -w "$WAITSECS" $SITE > cdn.txt

if [ -f ../site_parser.pl ]; then
	perl ../site_parser.pl
fi

sleep 5

cmd="$WPULL --warc-file $WARCNAME \
    --no-check-certificate \
    --no-robots \
    --delete-after \
    --$WAITPARAM \
    --tries=5 \
    --waitretry=20 \
    --random-wait \
    --strip-session-id \
    --user-agent=\"$USERAGENT\" \
    --header=\"$COOKIE\" \
    --warc-append \
    --database $WARCNAME-cdn.db \
    --input-file=cdn.txt \
    --warc-cdx"
# if [ -n "$CDXFILE" ]; then
#   cmd="$cmd \
#     --warc-dedup $CDXFILE"
# fi
echo "executing CDN Precrawl command $cmd"
#exec $cmd
$WPULL --warc-file $WARCNAME \
    --no-check-certificate \
    --no-robots \
    --delete-after \
    --$WAITPARAM \
    --tries=5 \
    --waitretry=20 \
    --random-wait \
    --strip-session-id \
    --user-agent="$USERAGENT" \
    --header="$COOKIE" \
    --warc-append \
    --database $WARCNAME-cdn.db \
    --input-file=cdn.txt \
    --warc-cdx
